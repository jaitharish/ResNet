{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28859b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "#from __future__ import print_function\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "from vis.visualization import visualize_activation, get_num_filters\n",
    "from vis.input_modifiers import Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64671143",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c644866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vis.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7082589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed = []\n",
    "    for point in points:\n",
    "        if smoothed:\n",
    "            previous = smoothed[-1]\n",
    "            smoothed.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed.append(point)\n",
    "    return smoothed\n",
    "\n",
    "def plot_compare(history, steps=-1):\n",
    "    if steps < 0:\n",
    "        steps = len(history.history['acc'])\n",
    "    acc = smooth_curve(history.history['acc'][:steps])\n",
    "    val_acc = smooth_curve(history.history['val_acc'][:steps])\n",
    "    loss = smooth_curve(history.history['loss'][:steps])\n",
    "    val_loss = smooth_curve(history.history['val_loss'][:steps])\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(loss, c='#0c7cba', label='Train Loss')\n",
    "    plt.plot(val_loss, c='#0f9d58', label='Val Loss')\n",
    "    plt.xticks(range(0, len(loss), 5))\n",
    "    plt.xlim(0, len(loss))\n",
    "    plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(acc, c='#0c7cba', label='Train Acc')\n",
    "    plt.plot(val_acc, c='#0f9d58', label='Val Acc')\n",
    "    plt.xticks(range(0, len(acc), 5))\n",
    "    plt.xlim(0, len(acc))\n",
    "    plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    "    \n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "        # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    " \n",
    "def save_history(history, fn):\n",
    "    with open(fn, 'wb') as fw:\n",
    "        pickle.dump(history.history, fw, protocol=2)\n",
    "\n",
    "def load_history(fn):\n",
    "    class Temp():\n",
    "        pass\n",
    "    history = Temp()\n",
    "    with open(fn, 'rb') as fr:\n",
    "        history.history = pickle.load(fr)\n",
    "    return history\n",
    "\n",
    "def jitter(img, amount=32):\n",
    "    ox, oy = np.random.randint(-amount, amount+1, 2)\n",
    "    return np.roll(np.roll(img, ox, -1), oy, -2), ox, oy\n",
    "\n",
    "def reverse_jitter(img, ox, oy):\n",
    "    return np.roll(np.roll(img, -ox, -1), -oy, -2)\n",
    "\n",
    "def plot_image(img):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c6417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1', \n",
    "                 input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2), name='maxpool_1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'))\n",
    "model.add(MaxPooling2D((2, 2), name='maxpool_2'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'))\n",
    "model.add(MaxPooling2D((2, 2), name='maxpool_3'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'))\n",
    "model.add(MaxPooling2D((2, 2), name='maxpool_4'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', name='dense_1'))\n",
    "model.add(Dense(256, activation='relu', name='dense_2'))\n",
    "model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e756cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 3 classes.\n",
      "Found 19 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'D:\\code\\data\\cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f4b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 44s 444ms/step - loss: -11659306278.5596 - accuracy: 0.2642 - val_loss: -134409936896.0000 - val_accuracy: 0.2632\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 45s 448ms/step - loss: -23025652513832.9609 - accuracy: 0.2632 - val_loss: -127697514659840.0000 - val_accuracy: 0.2632\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 46s 459ms/step - loss: -1648971733668987.0000 - accuracy: 0.2632 - val_loss: -5798253094240256.0000 - val_accuracy: 0.2632\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 46s 456ms/step - loss: -27973888596823244.0000 - accuracy: 0.2632 - val_loss: -72828746825990144.0000 - val_accuracy: 0.2632\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 46s 456ms/step - loss: -218537565680755008.0000 - accuracy: 0.2632 - val_loss: -467252584508293120.0000 - val_accuracy: 0.2632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=5, \n",
    "                              validation_data=validation_generator, validation_steps=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58aea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\code\\data\\cats_and_dogs_small\\model.h5')\n",
    "save_history(history, 'D:\\code\\data\\cats_and_dogs_small\\history.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6028a5f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0e52ea5f27b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\code\\data\\cats_and_dogs_small\\history.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-a0ac19b99f66>\u001b[0m in \u001b[0;36mplot_compare\u001b[1;34m(history, steps)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmooth_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmooth_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "history = load_history('D:\\code\\data\\cats_and_dogs_small\\history.bin')\n",
    "plot_compare(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = Sequential()\n",
    "model_aug.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1', \n",
    "                 input_shape=(150, 150, 3)))\n",
    "model_aug.add(MaxPooling2D((2, 2), name='maxpool_1'))\n",
    "model_aug.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'))\n",
    "model_aug.add(MaxPooling2D((2, 2), name='maxpool_2'))\n",
    "model_aug.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'))\n",
    "model_aug.add(MaxPooling2D((2, 2), name='maxpool_3'))\n",
    "model_aug.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'))\n",
    "model_aug.add(MaxPooling2D((2, 2), name='maxpool_4'))\n",
    "model_aug.add(Flatten())\n",
    "model_aug.add(Dropout(0.5))\n",
    "model_aug.add(Dense(512, activation='relu', name='dense_1'))\n",
    "model_aug.add(Dense(256, activation='relu', name='dense_2'))\n",
    "model_aug.add(Dense(1, activation='sigmoid', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c897db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 3 classes.\n",
      "Found 19 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
    "history_aug = model_aug.fit_generator(train_generator, steps_per_epoch=100, epochs=60, \n",
    "                                      validation_data=validation_generator, validation_steps=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'D:\\code\\data\\cats_and_dogs_small\\\\train\\jai\\img_1.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced55e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights='imagenet', include_top=False)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22eb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the outputs of the top 8 layers:\n",
    "layer_outputs = [layer.output for layer in vgg.layers if 'conv1' in layer.name]\n",
    "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
    "intermediate_activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = intermediate_activations[0]\n",
    "\n",
    "plt.imshow(first_layer_activation[0, :, :, 19], cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "\n",
    "layer_outputs = [layer.output for layer in vgg.layers if layer.name in layer_names]\n",
    "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
    "intermediate_activations = activation_model.predict(img_tensor)\n",
    "\n",
    "images_per_row = 8\n",
    "max_images = 8\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, intermediate_activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    n_features = min(n_features, max_images)\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 2. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.axis('off')\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VGG16 network with ImageNet weights\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# Utility to search for layer index by name. \n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = visualize_activation(model, layer_idx, filter_indices=20)\n",
    "plot_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation, get_num_filters\n",
    "img = visualize_activation(model, layer_idx, filter_indices=20)\n",
    "plot_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa13e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec812ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e700cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_filters = 40\n",
    "selected_indices = []\n",
    "vis_images = [[], [], [], [], []]\n",
    "i = 0\n",
    "selected_filters = [[0, 3, 11, 25, 26, 33, 42, 62], \n",
    "    [8, 21, 23, 38, 39, 45, 50, 79], \n",
    "    [40, 48, 52, 54, 81, 107, 224, 226],\n",
    "    [58, 79, 86, 216, 307, 426, 497, 509],\n",
    "    [2, 7, 41, 84, 103, 306, 461, 487]]\n",
    "\n",
    "for layer_name in ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']:\n",
    "    layer_idx = utils.find_layer_idx(model, layer_name)\n",
    "\n",
    "    # Visualize all filters in this layer.\n",
    "    if selected_filters:\n",
    "        filters = selected_filters[i]\n",
    "    else:\n",
    "        filters = sorted(np.random.permutation(get_num_filters(model.layers[layer_idx]))[:max_filters])\n",
    "    selected_indices.append(filters)\n",
    "\n",
    "    # Generate input image for each filter.\n",
    "    for idx in filters:\n",
    "        img = visualize_activation(model, layer_idx, filter_indices=idx, tv_weight=0., \n",
    "                                   input_modifiers=[Jitter(0.05)], max_iter=300) \n",
    "        vis_images[i].append(img)\n",
    "\n",
    "    # Generate stitched image palette with 4 cols so we get 2 rows.\n",
    "    stitched = utils.stitch_images(vis_images[i], cols=4)    \n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.title(layer_name)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(stitched)\n",
    "    plt.show()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = '''\n",
    "rabbit 330\n",
    "crocodile 49\n",
    "starfish 327\n",
    "husky 248\n",
    "goldfish 1\n",
    "bridge 839\n",
    "balloon 417\n",
    "tennis ball 852\n",
    "gondola 576\n",
    "dumbbell 543\n",
    "hammer 587\n",
    "lamp 846\n",
    "'''\n",
    "\n",
    "initial = []\n",
    "images = []\n",
    "tuples = []\n",
    "for line in codes.split('\\n'):\n",
    "    if not line:\n",
    "        continue\n",
    "    name, idx = line.rsplit(' ', 1)\n",
    "    idx = int(idx)\n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx, \n",
    "                               tv_weight=0., max_iter=300, input_modifiers=[Jitter(16)])\n",
    "\n",
    "    initial.append(img)\n",
    "    tuples.append((name, idx))\n",
    "\n",
    "i = 0\n",
    "for name, idx in tuples:\n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx,\n",
    "                               seed_input = initial[i], max_iter=300, input_modifiers=[Jitter(16)])\n",
    "    img = utils.draw_text(img, name)\n",
    "    i += 1\n",
    "    images.append(img)\n",
    "\n",
    "stitched = utils.stitch_images(images, cols=4)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis('off')\n",
    "plt.imshow(stitched)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vis_images = [[], [], [], [], []]\n",
    "i = 0\n",
    "for layer_name in ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']:\n",
    "    layer_idx = utils.find_layer_idx(model, layer_name)\n",
    "\n",
    "    # Generate input image for each filter.\n",
    "    for j, idx in enumerate(selected_indices[i]):\n",
    "        img = visualize_activation(model, layer_idx, filter_indices=idx, \n",
    "                                   seed_input=vis_images[i][j], input_modifiers=[Jitter(0.05)]) \n",
    "        img = utils.draw_text(img, 'Filter {}'.format(idx))  \n",
    "        new_vis_images[i].append(img)\n",
    "\n",
    "    stitched = utils.stitch_images(new_vis_images[i], cols=4)    \n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.title(layer_name)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(stitched)\n",
    "    plt.show()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53d60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
