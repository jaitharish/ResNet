{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-17T09:12:45.928584Z",
     "iopub.status.busy": "2021-12-17T09:12:45.928232Z",
     "iopub.status.idle": "2021-12-17T09:12:45.947891Z",
     "shell.execute_reply": "2021-12-17T09:12:45.947233Z",
     "shell.execute_reply.started": "2021-12-17T09:12:45.928549Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "Collecting audioread>=2.0.0 (from librosa)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/d1/e324634c5867a668774d6fe233a83228da4ba16521e19059c15df899737d/audioread-2.1.9.tar.gz (377kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (1.16.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (5.0.9)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from librosa) (1.16.0)\n",
      "Collecting resampy>=0.2.2 (from librosa)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/75/e22272b9c2185fc8f3af6ce37229708b45e8b855fd4bc38b4d6b040fff65/resampy-0.2.2.tar.gz (323kB)\n",
      "Collecting numba>=0.43.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/27/0a511b13ee6102125b678e2ad3544b451cddc72419325060823ebcdbdd56/numba-0.47.0-cp35-cp35m-win_amd64.whl\n",
      "Collecting soundfile>=0.9.0 (from librosa)\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/de/24e4035f06540ebb4e9993238ede787063875b003e79c537511d32a74d29/SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (689kB)\n",
      "Collecting llvmlite>=0.31.0dev0 (from numba>=0.43.0->librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/50/cc/04526507e80d546be5688ce0246e40277b61e7949c3347c6609b6a4154cf/llvmlite-0.32.1.tar.gz\n",
      "Requirement already satisfied: setuptools in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from numba>=0.43.0->librosa) (50.3.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Building wheels for collected packages: librosa, audioread, resampy, llvmlite\n",
      "  Running setup.py bdist_wheel for librosa: started\n",
      "  Running setup.py bdist_wheel for librosa: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jai t l harish\\AppData\\Local\\pip\\Cache\\wheels\\4c\\6e\\d7\\bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "  Running setup.py bdist_wheel for audioread: started\n",
      "  Running setup.py bdist_wheel for audioread: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jai t l harish\\AppData\\Local\\pip\\Cache\\wheels\\6d\\55\\fc\\0d9cb2a5a52cc24d86cfcd5db4d40f448a43b9a6046c019fc1\n",
      "  Running setup.py bdist_wheel for resampy: started\n",
      "  Running setup.py bdist_wheel for resampy: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jai t l harish\\AppData\\Local\\pip\\Cache\\wheels\\fa\\c1\\56\\e0e12c6f7f3d2cdea9712b35136a2d40a7817c6210ec096485\n",
      "  Running setup.py bdist_wheel for llvmlite: started\n",
      "  Running setup.py bdist_wheel for llvmlite: finished with status 'error'\n",
      "  Complete output from command \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\python.exe\" -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\JAITLH~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y6u0yddz\\\\llvmlite\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-wheel-2ekitqvz --python-tag cp35:\n",
      "  running bdist_wheel\n",
      "  C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\python.exe C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\n",
      "  Trying generator 'Visual Studio 14 2015 Win64'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 192, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 180, in main\n",
      "      main_win32()\n",
      "    File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 89, in main_win32\n",
      "      generator = find_win32_generator()\n",
      "    File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 77, in find_win32_generator\n",
      "      try_cmake(cmake_dir, build_dir, generator)\n",
      "    File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 28, in try_cmake\n",
      "      subprocess.check_call(['cmake', '-G', generator, cmake_dir])\n",
      "    File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 266, in check_call\n",
      "      retcode = call(*popenargs, **kwargs)\n",
      "    File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 247, in call\n",
      "      with Popen(*popenargs, **kwargs) as p:\n",
      "    File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 676, in __init__\n",
      "      restore_signals, start_new_session)\n",
      "    File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 957, in _execute_child\n",
      "      startupinfo)\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  error: command 'C:\\\\Users\\\\jai t l harish\\\\anaconda3\\\\envs\\\\tensorflow1\\\\python.exe' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for llvmlite\n",
      "Successfully built librosa audioread resampy\n",
      "Failed to build llvmlite\n",
      "Installing collected packages: audioread, llvmlite, numba, resampy, soundfile, librosa\n",
      "  Running setup.py install for llvmlite: started\n",
      "    Running setup.py install for llvmlite: finished with status 'error'\n",
      "    Complete output from command \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\python.exe\" -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\JAITLH~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y6u0yddz\\\\llvmlite\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-record-il2qwjny\\install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    got version from file C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\llvmlite/_version.py {'version': '0.32.1', 'full': 'aa11b129c0b55973067422397821ae6d44fa5e70'}\n",
      "    running build_ext\n",
      "    C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\python.exe C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\n",
      "    Trying generator 'Visual Studio 14 2015 Win64'\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 192, in <module>\n",
      "        main()\n",
      "      File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 180, in main\n",
      "        main_win32()\n",
      "      File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 89, in main_win32\n",
      "        generator = find_win32_generator()\n",
      "      File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 77, in find_win32_generator\n",
      "        try_cmake(cmake_dir, build_dir, generator)\n",
      "      File \"C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\ffi\\build.py\", line 28, in try_cmake\n",
      "        subprocess.check_call(['cmake', '-G', generator, cmake_dir])\n",
      "      File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 266, in check_call\n",
      "        retcode = call(*popenargs, **kwargs)\n",
      "      File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 247, in call\n",
      "        with Popen(*popenargs, **kwargs) as p:\n",
      "      File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 676, in __init__\n",
      "        restore_signals, start_new_session)\n",
      "      File \"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\lib\\subprocess.py\", line 957, in _execute_child\n",
      "        startupinfo)\n",
      "    FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "    error: command 'C:\\\\Users\\\\jai t l harish\\\\anaconda3\\\\envs\\\\tensorflow1\\\\python.exe' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for llvmlite\n",
      "mxnet-cu90mkl 1.5.0 has requirement requests<2.19.0,>=2.18.4, but you'll have requests 2.25.1 which is incompatible.\n",
      "mxnet 1.7.0.post2 has requirement requests<2.19.0,>=2.18.4, but you'll have requests 2.25.1 which is incompatible.\n",
      "Command \"\"C:\\Users\\jai t l harish\\anaconda3\\envs\\tensorflow1\\python.exe\" -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\JAITLH~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-y6u0yddz\\\\llvmlite\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-record-il2qwjny\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\JAITLH~1\\AppData\\Local\\Temp\\pip-install-y6u0yddz\\llvmlite\\\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:12:46.173623Z",
     "iopub.status.busy": "2021-12-17T09:12:46.173022Z",
     "iopub.status.idle": "2021-12-17T09:12:46.180574Z",
     "shell.execute_reply": "2021-12-17T09:12:46.179988Z",
     "shell.execute_reply.started": "2021-12-17T09:12:46.173587Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4032a41e375a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import librosa,librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython,IPython.display as ipd\n",
    "import pandas as pd\n",
    "import csv\n",
    "import keras\n",
    "import os, fnmatch\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import os, fnmatch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:12:46.263323Z",
     "iopub.status.busy": "2021-12-17T09:12:46.263033Z",
     "iopub.status.idle": "2021-12-17T09:12:46.267686Z",
     "shell.execute_reply": "2021-12-17T09:12:46.266678Z",
     "shell.execute_reply.started": "2021-12-17T09:12:46.263288Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../input/face-dataset/kria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:12:46.353665Z",
     "iopub.status.busy": "2021-12-17T09:12:46.353017Z",
     "iopub.status.idle": "2021-12-17T09:12:46.358026Z",
     "shell.execute_reply": "2021-12-17T09:12:46.357435Z",
     "shell.execute_reply.started": "2021-12-17T09:12:46.353617Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:12:48.212563Z",
     "iopub.status.busy": "2021-12-17T09:12:48.212183Z",
     "iopub.status.idle": "2021-12-17T09:13:04.791471Z",
     "shell.execute_reply": "2021-12-17T09:13:04.790115Z",
     "shell.execute_reply.started": "2021-12-17T09:12:48.212534Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install split-folders\n",
    "!pip install split-folders tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.793897Z",
     "iopub.status.busy": "2021-12-17T09:13:04.793548Z",
     "iopub.status.idle": "2021-12-17T09:13:04.879945Z",
     "shell.execute_reply": "2021-12-17T09:13:04.879121Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.793848Z"
    }
   },
   "outputs": [],
   "source": [
    "import splitfolders  # or import split_folders\n",
    " \n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(\"../input/face-dataset/kria\", output=\"train_test_split\", seed=1337, ratio=(.6, .3, .1), group_prefix=None) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.881668Z",
     "iopub.status.busy": "2021-12-17T09:13:04.881376Z",
     "iopub.status.idle": "2021-12-17T09:13:04.89824Z",
     "shell.execute_reply": "2021-12-17T09:13:04.897354Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.88162Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "import pydot\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "#from resnets_utils import *\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last') # can be channels_first or channels_last. \n",
    "K.set_learning_phase(1) # 1 stands for learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.901761Z",
     "iopub.status.busy": "2021-12-17T09:13:04.901135Z",
     "iopub.status.idle": "2021-12-17T09:13:04.916285Z",
     "shell.execute_reply": "2021-12-17T09:13:04.915422Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.901719Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, level, block_no, filters):\n",
    "    \"\"\"\n",
    "    Identity block as seen in figure 3.1\n",
    "    \n",
    "    Inputs:\n",
    "    X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in next section)\n",
    "    block_no - each level has multiple layers block_no will be n for the 'n'th layer in current block\n",
    "    filters - a list on integers, each of them defining the number of filters in each convolutional layer \n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    X - tensor (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    layers will be called {block_name}_1, {block_name}_2 and {block_name}_3 \n",
    "    eg: the 2nd convolutional layer in the 5th identity block in level 4 will be called \n",
    "    conv4_iden_5_2\n",
    "    \"\"\"\n",
    "    conv_base_name = 'conv' + str(level) + 'iden' + str(block_no)\n",
    "    norm_name = 'norm' + str(level) + 'iden' + str(block_no)\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # we will need this for the shortcut path\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters = f1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_base_name + '1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters = f2, kernel_size = (3, 3), strides = (1,1), padding = 'same', name = conv_base_name + '2', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '2')(X)\n",
    "    X = Activation('relu')(X)    \n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters = f3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_base_name + '3', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '3')(X)\n",
    "    \n",
    "    # shortcut\n",
    "    X = Add()([X, X_shortcut])\n",
    "    \n",
    "    # nonlinearity\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.918065Z",
     "iopub.status.busy": "2021-12-17T09:13:04.917621Z",
     "iopub.status.idle": "2021-12-17T09:13:04.949199Z",
     "shell.execute_reply": "2021-12-17T09:13:04.948358Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.918029Z"
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, level, block_no, filters, s = (2,2)):\n",
    "    \"\"\"\n",
    "    Convolutional block as seen in figure 3.1\n",
    "    \n",
    "    Inputs:\n",
    "    X - input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    block_no - each level has multiple layers; block_no will be n for the 'n'th layer in current block\n",
    "    filters - a list on integers, each of them defining the number of filters in each convolutional layer \n",
    "    level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in next section)\n",
    "    s - stride of the first layer; remember that the convolutional layer is used to change the dimension of X; an s=2 will reduce the width and height to half.\n",
    "    \n",
    "    Output:\n",
    "    X - tensor (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    layers will be called {block_name}_1, {block_name}_2 and {block_name}_3 \n",
    "    eg: the 2nd convolutional layer in the 5th identity block in level 4 will be called \n",
    "    conv4_iden_5_2\n",
    "    \"\"\"\n",
    "    conv_base_name = 'conv' + str(level) + 'conv' + str(block_no)\n",
    "    norm_name = 'conv' + str(level) + 'norm' + str(block_no)\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    # we will need this for the shortcut path\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters = f1, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_base_name + '1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters = f2, kernel_size = (3, 3), strides = (1,1), padding = 'same', name = conv_base_name + '2', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '2')(X)\n",
    "    X = Activation('relu')(X)    \n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters = f3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_base_name + '3', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = norm_name + '3')(X)\n",
    "    \n",
    "    # shortcut path\n",
    "    X_shortcut = Conv2D(filters = f3, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_base_name + 'short', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = norm_name + 'short')(X_shortcut)\n",
    "    \n",
    "    # shortcut\n",
    "    X = Add()([X, X_shortcut])\n",
    "    \n",
    "    # nonlinearity\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.951042Z",
     "iopub.status.busy": "2021-12-17T09:13:04.95063Z",
     "iopub.status.idle": "2021-12-17T09:13:04.96868Z",
     "shell.execute_reply": "2021-12-17T09:13:04.96799Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.951003Z"
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50L(input_size, classes):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implementation of the 50-layer ResNet model according to figure 4.1 above\n",
    "    \n",
    "    Inputs:\n",
    "    input_size - a (n_H, n_W, n_C) touple, the shape of our input images\n",
    "    classes - integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model - a Keras Model() instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a tensor placesholder for our input\n",
    "    X_input = Input(input_size)\n",
    "\n",
    "    ### Level 1 ###\n",
    "    # padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # convolutional layer, followed by batch normalization and relu activation\n",
    "    X = Conv2D(filters = 64, kernel_size = (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### Level 2 ###\n",
    "    # a max pooling layer\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level = 2, block_no = 1, filters = [64,64,256], s=(1,1))\n",
    "    # 2x identity blocks \n",
    "    X = identity_block(X, level = 2, block_no = 1, filters = [64,64,256])\n",
    "    X = identity_block(X, 2, 2, [64,64,256])\n",
    "    \n",
    "    ### Level 3 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level = 3, block_no = 1, filters = [128,128,512], s=(2,2))\n",
    "    # 3x identity blocks \n",
    "    X = identity_block(X, 3, 2, [128,128,512])\n",
    "    X = identity_block(X, 3, 3, [128,128,512])\n",
    "    X = identity_block(X, 3, 4, [128,128,512])\n",
    "    \n",
    "    ### Level 4 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level = 4, block_no = 1, filters = [256,256,1024], s=(2,2))\n",
    "    # 5x identity blocks \n",
    "    X = identity_block(X, 4, 2, [256,256,1024])\n",
    "    X = identity_block(X, 4, 3, [256,256,1024])\n",
    "    X = identity_block(X, 4, 4, [256,256,1024])\n",
    "    X = identity_block(X, 4, 5, [256,256,1024])\n",
    "    X = identity_block(X, 4, 6, [256,256,1024])\n",
    "    \n",
    "    ### Level 5 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level = 5, block_no = 1, filters = [512,512,2048], s=(2,2))\n",
    "    # 2x identity blocks \n",
    "    X = identity_block(X, 5, 2, [512,512,2048])\n",
    "    X = identity_block(X, 5, 3, [512,512,2048])\n",
    "    \n",
    "    # Pooling layers\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
    "    \n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fully_connected_' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50L')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.970372Z",
     "iopub.status.busy": "2021-12-17T09:13:04.969949Z",
     "iopub.status.idle": "2021-12-17T09:13:04.984909Z",
     "shell.execute_reply": "2021-12-17T09:13:04.984284Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.970341Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import *\n",
    "\n",
    "image = PIL.Image.open(\"./train_test_split/train/sana/0_IMG20211205135924_01.jpg\")\n",
    "#image to open\n",
    "\n",
    "width, height = image.size\n",
    "#extract width and height from output tuple\n",
    "\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:14:46.558174Z",
     "iopub.status.busy": "2021-12-17T09:14:46.557854Z",
     "iopub.status.idle": "2021-12-17T09:14:46.562932Z",
     "shell.execute_reply": "2021-12-17T09:14:46.562163Z",
     "shell.execute_reply.started": "2021-12-17T09:14:46.558143Z"
    }
   },
   "outputs": [],
   "source": [
    "Classes = 'jaia para sana'\n",
    "Classes = Classes.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:15:14.443238Z",
     "iopub.status.busy": "2021-12-17T09:15:14.442944Z",
     "iopub.status.idle": "2021-12-17T09:15:14.448908Z",
     "shell.execute_reply": "2021-12-17T09:15:14.448154Z",
     "shell.execute_reply.started": "2021-12-17T09:15:14.443206Z"
    }
   },
   "outputs": [],
   "source": [
    "Classes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:04.996624Z",
     "iopub.status.busy": "2021-12-17T09:13:04.995721Z",
     "iopub.status.idle": "2021-12-17T09:13:06.332187Z",
     "shell.execute_reply": "2021-12-17T09:13:06.33132Z",
     "shell.execute_reply.started": "2021-12-17T09:13:04.996589Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet50L(input_size = (112, 112, 3), classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:06.334842Z",
     "iopub.status.busy": "2021-12-17T09:13:06.33458Z",
     "iopub.status.idle": "2021-12-17T09:13:06.41193Z",
     "shell.execute_reply": "2021-12-17T09:13:06.411099Z",
     "shell.execute_reply.started": "2021-12-17T09:13:06.334811Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:06.41324Z",
     "iopub.status.busy": "2021-12-17T09:13:06.412979Z",
     "iopub.status.idle": "2021-12-17T09:13:06.427262Z",
     "shell.execute_reply": "2021-12-17T09:13:06.42637Z",
     "shell.execute_reply.started": "2021-12-17T09:13:06.413205Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', # optimizer\n",
    "    loss='categorical_crossentropy', # loss function to optimize \n",
    "    metrics=['accuracy'] # metrics to monitor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:06.428694Z",
     "iopub.status.busy": "2021-12-17T09:13:06.4284Z",
     "iopub.status.idle": "2021-12-17T09:13:06.43601Z",
     "shell.execute_reply": "2021-12-17T09:13:06.435431Z",
     "shell.execute_reply.started": "2021-12-17T09:13:06.428663Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:06.437616Z",
     "iopub.status.busy": "2021-12-17T09:13:06.436973Z",
     "iopub.status.idle": "2021-12-17T09:13:06.653181Z",
     "shell.execute_reply": "2021-12-17T09:13:06.652525Z",
     "shell.execute_reply.started": "2021-12-17T09:13:06.437588Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = \"./train_test_split/train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(112,112),color_mode=\"rgb\",class_mode='categorical',batch_size=16)\n",
    "\n",
    "validation_dir = \"./train_test_split/val\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(112, 112),color_mode='rgb',class_mode='categorical',batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:06.654919Z",
     "iopub.status.busy": "2021-12-17T09:13:06.654205Z",
     "iopub.status.idle": "2021-12-17T09:13:44.636689Z",
     "shell.execute_reply": "2021-12-17T09:13:44.635955Z",
     "shell.execute_reply.started": "2021-12-17T09:13:06.654857Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,epochs=15,validation_data=vali_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:44.638105Z",
     "iopub.status.busy": "2021-12-17T09:13:44.637912Z",
     "iopub.status.idle": "2021-12-17T09:13:46.111036Z",
     "shell.execute_reply": "2021-12-17T09:13:46.109945Z",
     "shell.execute_reply.started": "2021-12-17T09:13:44.638082Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:46.113633Z",
     "iopub.status.busy": "2021-12-17T09:13:46.113305Z",
     "iopub.status.idle": "2021-12-17T09:13:48.644024Z",
     "shell.execute_reply": "2021-12-17T09:13:48.643247Z",
     "shell.execute_reply.started": "2021-12-17T09:13:46.11359Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"my_model.h5\")\n",
    "reconstructed_model.layers[0].input_shape #(None, 432, 432, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:48.645515Z",
     "iopub.status.busy": "2021-12-17T09:13:48.645307Z",
     "iopub.status.idle": "2021-12-17T09:13:50.198658Z",
     "shell.execute_reply": "2021-12-17T09:13:50.197894Z",
     "shell.execute_reply.started": "2021-12-17T09:13:48.645489Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_path=\"./train_test_split/train/jaia/0_IMG_20211101_101606.jpg\"\n",
    "img = image.load_img(image_path, target_size=(112,112))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=reconstructed_model.predict(img)\n",
    "#plt.title(get_label_name(result[0][0]))\n",
    "#plt.show()\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:50.200022Z",
     "iopub.status.busy": "2021-12-17T09:13:50.19978Z",
     "iopub.status.idle": "2021-12-17T09:13:50.556331Z",
     "shell.execute_reply": "2021-12-17T09:13:50.555447Z",
     "shell.execute_reply.started": "2021-12-17T09:13:50.199992Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_path=\"./train_test_split/train/jaia/0_IMG_20211101_101644.jpg\"\n",
    "img = image.load_img(image_path, target_size=(112,112))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=reconstructed_model.predict(img)\n",
    "#plt.title(get_label_name(result[0][0]))\n",
    "#plt.show()\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T09:13:50.558309Z",
     "iopub.status.busy": "2021-12-17T09:13:50.557951Z",
     "iopub.status.idle": "2021-12-17T09:13:51.3907Z",
     "shell.execute_reply": "2021-12-17T09:13:51.389939Z",
     "shell.execute_reply.started": "2021-12-17T09:13:50.558266Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "image_path=\"./train_test_split/train/sana/0_IMG20211205135909.jpg\"\n",
    "img = image.load_img(image_path, target_size=(112,112))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=reconstructed_model.predict(img)\n",
    "#plt.title(get_label_name(result[0][0]))\n",
    "#plt.show()\n",
    "print (result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
